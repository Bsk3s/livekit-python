import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional

from fastapi import APIRouter, Request
from fastapi.responses import HTMLResponse
from spiritual_voice_agent.services.metrics_service import get_metrics_service

router = APIRouter()

# Comprehensive Latency Analysis Dashboard
LATENCY_DASHBOARD_HTML = """
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Agent Latency Analysis Dashboard</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body { 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
            margin: 0; padding: 20px; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }
        .container { max-width: 1400px; margin: 0 auto; }
        .header { text-align: center; margin-bottom: 30px; }
        .grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(400px, 1fr)); gap: 20px; }
        .card { 
            background: rgba(255,255,255,0.1); 
            border-radius: 15px; 
            padding: 20px; 
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.2);
        }
        .metric-value { font-size: 2.5em; font-weight: bold; color: #00ff88; }
        .metric-label { font-size: 0.9em; opacity: 0.8; margin-bottom: 10px; }
        .optimization-btn { 
            background: linear-gradient(45deg, #ff6b6b, #feca57); 
            border: none; 
            padding: 10px 20px; 
            border-radius: 25px; 
            color: white; 
            cursor: pointer; 
            margin: 5px;
            font-weight: bold;
        }
        .optimization-btn:hover { transform: translateY(-2px); box-shadow: 0 5px 15px rgba(0,0,0,0.3); }
        .critical { color: #ff6b6b; }
        .warning { color: #feca57; }
        .good { color: #00ff88; }
        .settings-panel { 
            background: rgba(0,0,0,0.3); 
            padding: 15px; 
            border-radius: 10px; 
            margin: 10px 0;
        }
        .component-breakdown { 
            display: grid; 
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); 
            gap: 10px; 
            margin: 15px 0;
        }
        .component-card {
            background: rgba(255,255,255,0.05);
            padding: 15px;
            border-radius: 8px;
            text-align: center;
        }
        .live-indicator { 
            width: 10px; height: 10px; 
            border-radius: 50%; 
            background: #00ff88; 
            display: inline-block; 
            margin-right: 10px;
            animation: pulse 2s infinite;
        }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1><span class="live-indicator"></span>Voice Agent Latency Analysis</h1>
            <p>Real-time performance monitoring & optimization dashboard</p>
        </div>

        <!-- Overall Pipeline Performance -->
        <div class="card">
            <h2>üéØ End-to-End Pipeline Performance</h2>
            <div class="component-breakdown">
                <div class="component-card">
                    <div class="metric-value" id="total-latency">--</div>
                    <div class="metric-label">Total Latency</div>
                </div>
                <div class="component-card">
                    <div class="metric-value" id="perceived-latency">--</div>
                    <div class="metric-label">Perceived Latency</div>
                </div>
                <div class="component-card">
                    <div class="metric-value" id="first-audio">--</div>
                    <div class="metric-label">First Audio</div>
                </div>
                <div class="component-card">
                    <div class="metric-value" id="completion-time">--</div>
                    <div class="metric-label">Completion</div>
                </div>
            </div>
            <canvas id="pipelineChart" width="400" height="200"></canvas>
        </div>

        <div class="grid">
            <!-- STT Analysis -->
            <div class="card">
                <h2>üé§ Speech-to-Text (STT) Analysis</h2>
                <div class="metric-value" id="stt-latency">--ms</div>
                <div class="metric-label">Current STT Latency</div>
                
                <div class="settings-panel">
                    <h4>üîß STT Optimization Options</h4>
                    <button class="optimization-btn" onclick="optimizeSTT('model')">Switch Model</button>
                    <button class="optimization-btn" onclick="optimizeSTT('config')">Tune Config</button>
                    <button class="optimization-btn" onclick="optimizeSTT('streaming')">Streaming Mode</button>
                    <button class="optimization-btn" onclick="optimizeSTT('language')">Language Specific</button>
                </div>
                
                <canvas id="sttChart" width="400" height="200"></canvas>
                
                <div id="stt-details">
                    <p><strong>Current:</strong> Deepgram Nova-2</p>
                    <p><strong>Real-time Factor:</strong> <span id="stt-rtf">--</span></p>
                    <p><strong>Accuracy:</strong> <span id="stt-accuracy">--</span>%</p>
                </div>
            </div>

            <!-- LLM Analysis -->
            <div class="card">
                <h2>üß† Language Model (LLM) Analysis</h2>
                <div class="metric-value" id="llm-latency">--ms</div>
                <div class="metric-label">Current LLM Latency</div>
                
                <div class="settings-panel">
                    <h4>‚ö° LLM Optimization Options</h4>
                    <button class="optimization-btn" onclick="optimizeLLM('model')">Switch Model</button>
                    <button class="optimization-btn" onclick="optimizeLLM('streaming')">Token Streaming</button>
                    <button class="optimization-btn" onclick="optimizeLLM('context')">Context Size</button>
                    <button class="optimization-btn" onclick="optimizeLLM('temperature')">Temperature</button>
                    <button class="optimization-btn" onclick="optimizeLLM('parallel')">Parallel Calls</button>
                </div>
                
                <canvas id="llmChart" width="400" height="200"></canvas>
                
                <div id="llm-details">
                    <p><strong>Current:</strong> GPT-4o-mini</p>
                    <p><strong>Tokens/sec:</strong> <span id="llm-tokens-sec">--</span></p>
                    <p><strong>Streaming:</strong> <span id="llm-streaming">--</span></p>
                </div>
            </div>

            <!-- TTS Analysis -->
            <div class="card">
                <h2>üîä Text-to-Speech (TTS) Analysis</h2>
                <div class="metric-value" id="tts-latency">--ms</div>
                <div class="metric-label">Current TTS Latency</div>
                
                <div class="settings-panel">
                    <h4>üéµ TTS Optimization Options</h4>
                    <button class="optimization-btn" onclick="optimizeTTS('model')">Switch Model</button>
                    <button class="optimization-btn" onclick="optimizeTTS('gpu')">GPU Acceleration</button>
                    <button class="optimization-btn" onclick="optimizeTTS('chunking')">Smart Chunking</button>
                    <button class="optimization-btn" onclick="optimizeTTS('quality')">Quality vs Speed</button>
                    <button class="optimization-btn" onclick="optimizeTTS('streaming')">Streaming Audio</button>
                </div>
                
                <canvas id="ttsChart" width="400" height="200"></canvas>
                
                <div id="tts-details">
                    <p><strong>Current:</strong> Kokoro (GPU)</p>
                    <p><strong>Sample Rate:</strong> <span id="tts-sample-rate">--</span> kHz</p>
                    <p><strong>Chunk Size:</strong> <span id="tts-chunk-size">--</span> chars</p>
                </div>
            </div>

            <!-- Pipeline Extras Analysis -->
            <div class="card">
                <h2>‚öôÔ∏è Pipeline Extras Analysis</h2>
                <div class="metric-value" id="extras-latency">--ms</div>
                <div class="metric-label">Pipeline Overhead</div>
                
                <div class="settings-panel">
                    <h4>üîß System Optimization Options</h4>
                    <button class="optimization-btn" onclick="optimizeExtras('network')">Network Tuning</button>
                    <button class="optimization-btn" onclick="optimizeExtras('memory')">Memory Optimization</button>
                    <button class="optimization-btn" onclick="optimizeExtras('concurrency')">Concurrency</button>
                    <button class="optimization-btn" onclick="optimizeExtras('buffering')">Buffer Tuning</button>
                    <button class="optimization-btn" onclick="optimizeExtras('audio')">Audio Processing</button>
                </div>
                
                <canvas id="extrasChart" width="400" height="200"></canvas>
                
                <div id="extras-breakdown">
                    <div class="component-breakdown">
                        <div class="component-card">
                            <div class="metric-value" id="network-latency">--</div>
                            <div class="metric-label">Network</div>
                        </div>
                        <div class="component-card">
                            <div class="metric-value" id="audio-processing">--</div>
                            <div class="metric-label">Audio Proc</div>
                        </div>
                        <div class="component-card">
                            <div class="metric-value" id="queue-delays">--</div>
                            <div class="metric-label">Queue Delays</div>
                        </div>
                        <div class="component-card">
                            <div class="metric-value" id="memory-overhead">--</div>
                            <div class="metric-label">Memory</div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Live Testing Laboratory -->
            <div class="card">
                <h2>üß™ Live Testing Laboratory</h2>
                <div class="settings-panel">
                    <h4>Test Configuration</h4>
                    <select id="test-character">
                        <option value="adina">Adina (Spiritual Guide)</option>
                        <option value="raffa">Raffa (Supportive Friend)</option>
                    </select>
                    <br><br>
                    <textarea id="test-input" placeholder="Enter test message or use voice input..." rows="3" style="width: 100%; background: rgba(255,255,255,0.1); border: 1px solid rgba(255,255,255,0.3); color: white; border-radius: 5px; padding: 10px;"></textarea>
                    <br><br>
                    <button class="optimization-btn" onclick="startVoiceTest()">üé§ Voice Test</button>
                    <button class="optimization-btn" onclick="startTextTest()">üìù Text Test</button>
                    <button class="optimization-btn" onclick="runBenchmark()">‚ö° Benchmark</button>
                </div>
                
                <div id="test-results">
                    <h4>Latest Test Results:</h4>
                    <div id="test-output"></div>
                </div>
            </div>

            <!-- Cost Impact Analysis -->
            <div class="card">
                <h2>üí∞ Cost Impact Analysis</h2>
                <div class="component-breakdown">
                    <div class="component-card">
                        <div class="metric-value" id="cost-per-minute">$--</div>
                        <div class="metric-label">Cost/Minute</div>
                    </div>
                    <div class="component-card">
                        <div class="metric-value" id="monthly-projection">$--</div>
                        <div class="metric-label">Monthly Est.</div>
                    </div>
                </div>
                
                <div id="cost-breakdown">
                    <p><strong>STT Cost:</strong> $<span id="stt-cost">--</span>/min</p>
                    <p><strong>LLM Cost:</strong> $<span id="llm-cost">--</span>/min</p>
                    <p><strong>TTS Cost:</strong> $<span id="tts-cost">--</span>/min</p>
                    <p><strong>Hosting:</strong> $<span id="hosting-cost">--</span>/min</p>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Initialize charts
        let charts = {};
        
        function initCharts() {
            const chartConfig = {
                type: 'line',
                options: {
                    responsive: true,
                    plugins: { legend: { labels: { color: 'white' } } },
                    scales: {
                        x: { ticks: { color: 'white' }, grid: { color: 'rgba(255,255,255,0.1)' } },
                        y: { ticks: { color: 'white' }, grid: { color: 'rgba(255,255,255,0.1)' } }
                    }
                }
            };
            
            // Pipeline Chart
            charts.pipeline = new Chart(document.getElementById('pipelineChart'), {
                ...chartConfig,
                data: {
                    labels: [],
                    datasets: [{
                        label: 'Total Latency',
                        data: [],
                        borderColor: '#ff6b6b',
                        backgroundColor: 'rgba(255,107,107,0.1)'
                    }, {
                        label: 'Perceived Latency',
                        data: [],
                        borderColor: '#00ff88',
                        backgroundColor: 'rgba(0,255,136,0.1)'
                    }]
                }
            });
            
            // Component Charts
            ['stt', 'llm', 'tts', 'extras'].forEach(component => {
                charts[component] = new Chart(document.getElementById(component + 'Chart'), {
                    ...chartConfig,
                    data: {
                        labels: [],
                        datasets: [{
                            label: component.toUpperCase() + ' Latency',
                            data: [],
                            borderColor: getComponentColor(component),
                            backgroundColor: getComponentColor(component, 0.1)
                        }]
                    }
                });
            });
        }
        
        function getComponentColor(component, alpha = 1) {
            const colors = {
                stt: `rgba(255, 107, 107, ${alpha})`,
                llm: `rgba(254, 202, 87, ${alpha})`,
                tts: `rgba(0, 255, 136, ${alpha})`,
                extras: `rgba(102, 126, 234, ${alpha})`
            };
            return colors[component];
        }
        
        // Optimization Functions
        function optimizeSTT(type) {
            console.log('Optimizing STT:', type);
            fetch('/api/optimize/stt', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ optimization_type: type })
            }).then(response => response.json())
              .then(data => updateResults(data));
        }
        
        function optimizeLLM(type) {
            console.log('Optimizing LLM:', type);
            fetch('/api/optimize/llm', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ optimization_type: type })
            }).then(response => response.json())
              .then(data => updateResults(data));
        }
        
        function optimizeTTS(type) {
            console.log('Optimizing TTS:', type);
            fetch('/api/optimize/tts', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ optimization_type: type })
            }).then(response => response.json())
              .then(data => updateResults(data));
        }
        
        function optimizeExtras(type) {
            console.log('Optimizing Pipeline Extras:', type);
            fetch('/api/optimize/extras', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ optimization_type: type })
            }).then(response => response.json())
              .then(data => updateResults(data));
        }
        
        // Testing Functions
        function startVoiceTest() {
            const character = document.getElementById('test-character').value;
            console.log('Starting voice test with character:', character);
            // Implement voice testing
        }
        
        function startTextTest() {
            const character = document.getElementById('test-character').value;
            const input = document.getElementById('test-input').value;
            console.log('Starting text test:', { character, input });
            
            fetch('/api/test/text', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ character, input })
            }).then(response => response.json())
              .then(data => displayTestResults(data));
        }
        
        function runBenchmark() {
            console.log('Running benchmark...');
            fetch('/api/benchmark')
                .then(response => response.json())
                .then(data => displayTestResults(data));
        }
        
        function displayTestResults(data) {
            const output = document.getElementById('test-output');
            output.innerHTML = `
                <div style="background: rgba(0,0,0,0.3); padding: 10px; border-radius: 5px; margin: 10px 0;">
                    <strong>Test completed at ${new Date().toLocaleTimeString()}</strong><br>
                    Total Latency: ${data.total_latency || '--'}ms<br>
                    STT: ${data.stt_latency || '--'}ms | 
                    LLM: ${data.llm_latency || '--'}ms | 
                    TTS: ${data.tts_latency || '--'}ms<br>
                    ${data.message ? 'Message: ' + data.message : ''}
                </div>
            `;
        }
        
        // Data Loading
        function loadLatencyData() {
            fetch('/api/latency/current')
                .then(response => response.json())
                .then(data => updateDashboard(data))
                .catch(error => console.error('Error loading data:', error));
        }
        
        function updateDashboard(data) {
            // Update main metrics
            document.getElementById('total-latency').textContent = (data.total_latency || '--') + 'ms';
            document.getElementById('perceived-latency').textContent = (data.perceived_latency || '--') + 'ms';
            document.getElementById('first-audio').textContent = (data.first_audio || '--') + 'ms';
            document.getElementById('completion-time').textContent = (data.completion_time || '--') + 'ms';
            
            // Update component metrics
            document.getElementById('stt-latency').textContent = (data.stt_latency || '--');
            document.getElementById('llm-latency').textContent = (data.llm_latency || '--');
            document.getElementById('tts-latency').textContent = (data.tts_latency || '--');
            document.getElementById('extras-latency').textContent = (data.extras_latency || '--');
            
            // Update details
            document.getElementById('stt-rtf').textContent = data.stt_rtf || '--';
            document.getElementById('stt-accuracy').textContent = data.stt_accuracy || '--';
            document.getElementById('llm-tokens-sec').textContent = data.llm_tokens_sec || '--';
            document.getElementById('llm-streaming').textContent = data.llm_streaming || 'Unknown';
            document.getElementById('tts-sample-rate').textContent = data.tts_sample_rate || '--';
            document.getElementById('tts-chunk-size').textContent = data.tts_chunk_size || '--';
            
            // Update extras breakdown
            document.getElementById('network-latency').textContent = (data.network_latency || '--') + 'ms';
            document.getElementById('audio-processing').textContent = (data.audio_processing || '--') + 'ms';
            document.getElementById('queue-delays').textContent = (data.queue_delays || '--') + 'ms';
            document.getElementById('memory-overhead').textContent = (data.memory_overhead || '--') + 'ms';
            
            // Update costs
            document.getElementById('cost-per-minute').textContent = '$' + (data.cost_per_minute || '--');
            document.getElementById('monthly-projection').textContent = '$' + (data.monthly_projection || '--');
            document.getElementById('stt-cost').textContent = data.stt_cost || '--';
            document.getElementById('llm-cost').textContent = data.llm_cost || '--';
            document.getElementById('tts-cost').textContent = data.tts_cost || '--';
            document.getElementById('hosting-cost').textContent = data.hosting_cost || '--';
            
            // Update charts
            updateCharts(data);
        }
        
        function updateCharts(data) {
            const timestamp = new Date().toLocaleTimeString();
            
            // Update pipeline chart
            if (charts.pipeline) {
                charts.pipeline.data.labels.push(timestamp);
                charts.pipeline.data.datasets[0].data.push(data.total_latency || 0);
                charts.pipeline.data.datasets[1].data.push(data.perceived_latency || 0);
                
                // Keep only last 20 data points
                if (charts.pipeline.data.labels.length > 20) {
                    charts.pipeline.data.labels.shift();
                    charts.pipeline.data.datasets.forEach(dataset => dataset.data.shift());
                }
                
                charts.pipeline.update();
            }
            
            // Update component charts
            ['stt', 'llm', 'tts', 'extras'].forEach(component => {
                if (charts[component]) {
                    charts[component].data.labels.push(timestamp);
                    charts[component].data.datasets[0].data.push(data[component + '_latency'] || 0);
                    
                    if (charts[component].data.labels.length > 20) {
                        charts[component].data.labels.shift();
                        charts[component].data.datasets[0].data.shift();
                    }
                    
                    charts[component].update();
                }
            });
        }
        
        // Initialize
        document.addEventListener('DOMContentLoaded', function() {
            initCharts();
            loadLatencyData();
            
            // Auto-refresh every 5 seconds
            setInterval(loadLatencyData, 5000);
        });
    </script>
</body>
</html>
"""

@router.get("/latency-dashboard", response_class=HTMLResponse)
async def latency_dashboard():
    """Comprehensive latency analysis dashboard."""
    return HTMLResponse(content=LATENCY_DASHBOARD_HTML)

@router.get("/api/latency/current")
async def get_current_latency():
    """Get current latency metrics for all components."""
    try:
        metrics_service = get_metrics_service()
        
        # Get latest metrics from the service
        summary = metrics_service.get_performance_summary(hours=1)
        
        if not summary or summary.get('total_requests', 0) == 0:
            # Return default/empty metrics
            return {
                'total_latency': 0,
                'perceived_latency': 0,
                'first_audio': 0,
                'completion_time': 0,
                'stt_latency': 0,
                'llm_latency': 0,
                'tts_latency': 0,
                'extras_latency': 0,
                'stt_rtf': 0,
                'stt_accuracy': 0,
                'llm_tokens_sec': 0,
                'llm_streaming': 'Unknown',
                'tts_sample_rate': 16,
                'tts_chunk_size': 50,
                'network_latency': 0,
                'audio_processing': 0,
                'queue_delays': 0,
                'memory_overhead': 0,
                'cost_per_minute': 0.012,
                'monthly_projection': 0,
                'stt_cost': 0.006,
                'llm_cost': 0.004,
                'tts_cost': 0.000,
                'hosting_cost': 0.002
            }
        
        # Calculate component latencies
        stage_breakdown = summary.get('stage_breakdown', {})
        stt_latency = stage_breakdown.get('stt_avg_ms', 0)
        llm_latency = stage_breakdown.get('llm_avg_ms', 0) 
        tts_latency = stage_breakdown.get('tts_avg_ms', 0)
        total_latency = summary.get('avg_latency_ms', 0)
        
        # Estimate pipeline extras (network, audio processing, etc.)
        extras_latency = max(0, total_latency - stt_latency - llm_latency - tts_latency)
        
        # Calculate perceived latency (time to first audio)
        perceived_latency = stt_latency + llm_latency + (tts_latency * 0.3)  # First TTS chunk
        
        # Get streaming metrics
        streaming_metrics = summary.get('streaming_metrics', {})
        
        return {
            'total_latency': int(total_latency),
            'perceived_latency': int(perceived_latency),
            'first_audio': int(streaming_metrics.get('first_token_avg_ms', perceived_latency)),
            'completion_time': int(total_latency),
            'stt_latency': int(stt_latency),
            'llm_latency': int(llm_latency),
            'tts_latency': int(tts_latency),
            'extras_latency': int(extras_latency),
            'stt_rtf': 0.85,
            'stt_accuracy': 94,
            'llm_tokens_sec': streaming_metrics.get('avg_tokens_per_second', 45),
            'llm_streaming': 'Enabled' if streaming_metrics.get('streaming_usage_pct', 0) > 50 else 'Disabled',
            'tts_sample_rate': 16,
            'tts_chunk_size': 50,
            'network_latency': int(extras_latency * 0.3),
            'audio_processing': int(extras_latency * 0.4),
            'queue_delays': int(extras_latency * 0.2),
            'memory_overhead': int(extras_latency * 0.1),
            'cost_per_minute': 0.012,
            'monthly_projection': int(0.012 * 60 * 24 * 30),
            'stt_cost': 0.006,
            'llm_cost': 0.004,
            'tts_cost': 0.000,
            'hosting_cost': 0.002
        }
        
    except Exception as e:
        print(f"Error getting current latency: {e}")
        return {'error': str(e)}, 500

@router.post("/api/optimize/{component}")
async def optimize_component(component: str, request: Request):
    """Handle optimization requests for different components."""
    try:
        data = await request.json()
        optimization_type = data.get('optimization_type')
        
        print(f"Optimization request: {component} - {optimization_type}")
        
        # This is where you'd implement actual optimizations
        # For now, return a mock response
        return {
            'success': True,
            'component': component,
            'optimization': optimization_type,
            'message': f'Applied {optimization_type} optimization to {component}',
            'estimated_improvement': '15-25ms faster'
        }
        
    except Exception as e:
        return {'error': str(e)}, 500

@router.post("/api/test/text")
async def test_text_pipeline(request: Request):
    """Test the text pipeline with timing."""
    try:
        data = await request.json()
        character = data.get('character', 'adina')
        input_text = data.get('input', 'Hello, how are you?')
        
        start_time = time.time()
        
        # This is where you'd run the actual pipeline test
        # For now, return mock timing data
        
        end_time = time.time()
        total_latency = int((end_time - start_time) * 1000)
        
        return {
            'success': True,
            'total_latency': total_latency,
            'stt_latency': 150,
            'llm_latency': 800,
            'tts_latency': 900,
            'character': character,
            'input': input_text,
            'message': 'Test pipeline completed successfully'
        }
        
    except Exception as e:
        return {'error': str(e)}, 500

@router.get("/api/benchmark")
async def run_benchmark():
    """Run a comprehensive benchmark test."""
    try:
        # This would run actual benchmark tests
        # For now, return mock data
        
        return {
            'success': True,
            'total_latency': 2100,
            'stt_latency': 180,
            'llm_latency': 850,
            'tts_latency': 920,
            'extras_latency': 150,
            'benchmark_type': 'comprehensive',
            'message': 'Benchmark completed - 5 test runs averaged'
        }
        
    except Exception as e:
        return {'error': str(e)}, 500

# Legacy metrics endpoint for backward compatibility
@router.get("/metrics", response_class=HTMLResponse)
async def metrics_dashboard():
    """Legacy metrics dashboard endpoint - redirects to latency dashboard"""
    return HTMLResponse(content=LATENCY_DASHBOARD_HTML) 